// Code generated by SQLBoiler 4.19.5 (https://github.com/aarondl/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/aarondl/null/v8"
	"github.com/aarondl/sqlboiler/v4/boil"
	"github.com/aarondl/sqlboiler/v4/queries"
	"github.com/aarondl/sqlboiler/v4/queries/qm"
	"github.com/aarondl/sqlboiler/v4/queries/qmhelper"
	"github.com/aarondl/strmangle"
	"github.com/friendsofgo/errors"
)

// APIKeysStatus is an object representing the database table.
type APIKeysStatus struct {
	ID         null.Int64  `boil:"id" json:"id,omitempty" toml:"id" yaml:"id,omitempty"`
	LogbookID  null.Int64  `boil:"logbook_id" json:"logbook_id,omitempty" toml:"logbook_id" yaml:"logbook_id,omitempty"`
	KeyName    null.String `boil:"key_name" json:"key_name,omitempty" toml:"key_name" yaml:"key_name,omitempty"`
	KeyPrefix  null.String `boil:"key_prefix" json:"key_prefix,omitempty" toml:"key_prefix" yaml:"key_prefix,omitempty"`
	CreatedAt  null.Time   `boil:"created_at" json:"created_at,omitempty" toml:"created_at" yaml:"created_at,omitempty"`
	LastUsedAt null.Time   `boil:"last_used_at" json:"last_used_at,omitempty" toml:"last_used_at" yaml:"last_used_at,omitempty"`
	ExpiresAt  null.Time   `boil:"expires_at" json:"expires_at,omitempty" toml:"expires_at" yaml:"expires_at,omitempty"`
	RevokedAt  null.Time   `boil:"revoked_at" json:"revoked_at,omitempty" toml:"revoked_at" yaml:"revoked_at,omitempty"`
	IsActive   null.Bool   `boil:"is_active" json:"is_active,omitempty" toml:"is_active" yaml:"is_active,omitempty"`
}

var APIKeysStatusColumns = struct {
	ID         string
	LogbookID  string
	KeyName    string
	KeyPrefix  string
	CreatedAt  string
	LastUsedAt string
	ExpiresAt  string
	RevokedAt  string
	IsActive   string
}{
	ID:         "id",
	LogbookID:  "logbook_id",
	KeyName:    "key_name",
	KeyPrefix:  "key_prefix",
	CreatedAt:  "created_at",
	LastUsedAt: "last_used_at",
	ExpiresAt:  "expires_at",
	RevokedAt:  "revoked_at",
	IsActive:   "is_active",
}

var APIKeysStatusTableColumns = struct {
	ID         string
	LogbookID  string
	KeyName    string
	KeyPrefix  string
	CreatedAt  string
	LastUsedAt string
	ExpiresAt  string
	RevokedAt  string
	IsActive   string
}{
	ID:         "api_keys_status.id",
	LogbookID:  "api_keys_status.logbook_id",
	KeyName:    "api_keys_status.key_name",
	KeyPrefix:  "api_keys_status.key_prefix",
	CreatedAt:  "api_keys_status.created_at",
	LastUsedAt: "api_keys_status.last_used_at",
	ExpiresAt:  "api_keys_status.expires_at",
	RevokedAt:  "api_keys_status.revoked_at",
	IsActive:   "api_keys_status.is_active",
}

// Generated where

var APIKeysStatusWhere = struct {
	ID         whereHelpernull_Int64
	LogbookID  whereHelpernull_Int64
	KeyName    whereHelpernull_String
	KeyPrefix  whereHelpernull_String
	CreatedAt  whereHelpernull_Time
	LastUsedAt whereHelpernull_Time
	ExpiresAt  whereHelpernull_Time
	RevokedAt  whereHelpernull_Time
	IsActive   whereHelpernull_Bool
}{
	ID:         whereHelpernull_Int64{field: "\"api_keys_status\".\"id\""},
	LogbookID:  whereHelpernull_Int64{field: "\"api_keys_status\".\"logbook_id\""},
	KeyName:    whereHelpernull_String{field: "\"api_keys_status\".\"key_name\""},
	KeyPrefix:  whereHelpernull_String{field: "\"api_keys_status\".\"key_prefix\""},
	CreatedAt:  whereHelpernull_Time{field: "\"api_keys_status\".\"created_at\""},
	LastUsedAt: whereHelpernull_Time{field: "\"api_keys_status\".\"last_used_at\""},
	ExpiresAt:  whereHelpernull_Time{field: "\"api_keys_status\".\"expires_at\""},
	RevokedAt:  whereHelpernull_Time{field: "\"api_keys_status\".\"revoked_at\""},
	IsActive:   whereHelpernull_Bool{field: "\"api_keys_status\".\"is_active\""},
}

var (
	apiKeysStatusAllColumns            = []string{"id", "logbook_id", "key_name", "key_prefix", "created_at", "last_used_at", "expires_at", "revoked_at", "is_active"}
	apiKeysStatusColumnsWithoutDefault = []string{}
	apiKeysStatusColumnsWithDefault    = []string{"id", "logbook_id", "key_name", "key_prefix", "created_at", "last_used_at", "expires_at", "revoked_at", "is_active"}
	apiKeysStatusPrimaryKeyColumns     = []string{}
	apiKeysStatusGeneratedColumns      = []string{}
)

type (
	// APIKeysStatusSlice is an alias for a slice of pointers to APIKeysStatus.
	// This should almost always be used instead of []APIKeysStatus.
	APIKeysStatusSlice []*APIKeysStatus

	apiKeysStatusQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	apiKeysStatusType           = reflect.TypeOf(&APIKeysStatus{})
	apiKeysStatusMapping        = queries.MakeStructMapping(apiKeysStatusType)
	apiKeysStatusInsertCacheMut sync.RWMutex
	apiKeysStatusInsertCache    = make(map[string]insertCache)
	apiKeysStatusUpdateCacheMut sync.RWMutex
	apiKeysStatusUpdateCache    = make(map[string]updateCache)
	apiKeysStatusUpsertCacheMut sync.RWMutex
	apiKeysStatusUpsertCache    = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
	// These are used in some views
	_ = fmt.Sprintln("")
	_ = reflect.Int
	_ = strings.Builder{}
	_ = sync.Mutex{}
	_ = strmangle.Plural("")
	_ = strconv.IntSize
)

// One returns a single apiKeysStatus record from the query.
func (q apiKeysStatusQuery) One(ctx context.Context, exec boil.ContextExecutor) (*APIKeysStatus, error) {
	o := &APIKeysStatus{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for api_keys_status")
	}

	return o, nil
}

// All returns all APIKeysStatus records from the query.
func (q apiKeysStatusQuery) All(ctx context.Context, exec boil.ContextExecutor) (APIKeysStatusSlice, error) {
	var o []*APIKeysStatus

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to APIKeysStatus slice")
	}

	return o, nil
}

// Count returns the count of all APIKeysStatus records in the query.
func (q apiKeysStatusQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count api_keys_status rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q apiKeysStatusQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if api_keys_status exists")
	}

	return count > 0, nil
}

// APIKeysStatuses retrieves all the records using an executor.
func APIKeysStatuses(mods ...qm.QueryMod) apiKeysStatusQuery {
	mods = append(mods, qm.From("\"api_keys_status\""))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"\"api_keys_status\".*"})
	}

	return apiKeysStatusQuery{q}
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *APIKeysStatus) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no api_keys_status provided for insertion")
	}

	var err error
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.CreatedAt).IsZero() {
			queries.SetScanner(&o.CreatedAt, currTime)
		}
	}

	nzDefaults := queries.NonZeroDefaultSet(apiKeysStatusColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	apiKeysStatusInsertCacheMut.RLock()
	cache, cached := apiKeysStatusInsertCache[key]
	apiKeysStatusInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			apiKeysStatusAllColumns,
			apiKeysStatusColumnsWithDefault,
			apiKeysStatusColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(apiKeysStatusType, apiKeysStatusMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(apiKeysStatusType, apiKeysStatusMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"api_keys_status\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"api_keys_status\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			queryReturning = fmt.Sprintf(" RETURNING \"%s\"", strings.Join(returnColumns, "\",\""))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}

	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into api_keys_status")
	}

	if !cached {
		apiKeysStatusInsertCacheMut.Lock()
		apiKeysStatusInsertCache[key] = cache
		apiKeysStatusInsertCacheMut.Unlock()
	}

	return nil
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *APIKeysStatus) Upsert(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, opts ...UpsertOptionFunc) error {
	if o == nil {
		return errors.New("models: no api_keys_status provided for upsert")
	}
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.CreatedAt).IsZero() {
			queries.SetScanner(&o.CreatedAt, currTime)
		}
	}

	nzDefaults := queries.NonZeroDefaultSet(apiKeysStatusColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	if updateOnConflict {
		buf.WriteByte('t')
	} else {
		buf.WriteByte('f')
	}
	buf.WriteByte('.')
	for _, c := range conflictColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	apiKeysStatusUpsertCacheMut.RLock()
	cache, cached := apiKeysStatusUpsertCache[key]
	apiKeysStatusUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, _ := insertColumns.InsertColumnSet(
			apiKeysStatusAllColumns,
			apiKeysStatusColumnsWithDefault,
			apiKeysStatusColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			apiKeysStatusAllColumns,
			apiKeysStatusPrimaryKeyColumns,
		)

		if updateOnConflict && len(update) == 0 {
			return errors.New("models: unable to upsert api_keys_status, could not build update column list")
		}

		ret := strmangle.SetComplement(apiKeysStatusAllColumns, strmangle.SetIntersect(insert, update))

		conflict := conflictColumns
		if len(conflict) == 0 && updateOnConflict && len(update) != 0 {
			if len(apiKeysStatusPrimaryKeyColumns) == 0 {
				return errors.New("models: unable to upsert api_keys_status, could not build conflict column list")
			}

			conflict = make([]string, len(apiKeysStatusPrimaryKeyColumns))
			copy(conflict, apiKeysStatusPrimaryKeyColumns)
		}
		cache.query = buildUpsertQueryPostgres(dialect, "\"api_keys_status\"", updateOnConflict, ret, update, conflict, insert, opts...)

		cache.valueMapping, err = queries.BindMapping(apiKeysStatusType, apiKeysStatusMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(apiKeysStatusType, apiKeysStatusMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(returns...)
		if errors.Is(err, sql.ErrNoRows) {
			err = nil // Postgres doesn't return anything when there's no update
		}
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}
	if err != nil {
		return errors.Wrap(err, "models: unable to upsert api_keys_status")
	}

	if !cached {
		apiKeysStatusUpsertCacheMut.Lock()
		apiKeysStatusUpsertCache[key] = cache
		apiKeysStatusUpsertCacheMut.Unlock()
	}

	return nil
}
